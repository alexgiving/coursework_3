{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_recall_fscore_support, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define mark which will  set min mark limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('dataset.xlsx')\n",
    "data.dropna\n",
    "\n",
    "min_mark = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(len(data['Средний балл']))\n",
    "y = data['Средний балл']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replase mark of student by belonging to the class of successfully passed\n",
    "data['Сдал'] = pd.cut(x=data['Средний балл'], bins=[0, min_mark, 10], labels=[0, 1])\n",
    "data.drop(['Средний балл'], axis = 1, inplace= True)\n",
    "\n",
    "# Drop indicators which are not connected with extracurricular activities\n",
    "data.drop([ 'Учащийся',\n",
    "            'Дата прохождения теста',\n",
    "            '15.Образование Ваших родителей?', \n",
    "            '3.С какими оценками Вы закончили школу?',\n",
    "            '4.Ходили ли Вы на подготовительные курсы перед поступлением в вуз?',\n",
    "            '7.Какая у Вас семья?',\n",
    "            '10.Получали ли Вы стипендию? (в течение последнего года)',\n",
    "            '11.Оцените, как Вам нравится учиться?'],\n",
    "            axis = 1, inplace = True)\n",
    "            \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find out how many students did not pass the exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passed = 0\n",
    "not_passed = 0\n",
    "res = 0\n",
    "for i in data['Сдал']:\n",
    "    if i == 1:\n",
    "        passed += 1\n",
    "    elif i == 0:\n",
    "        not_passed += 1\n",
    "    res += 1\n",
    "print(f\"TOTAL: {res}\\nPassed: {passed}\\nNot pas: {not_passed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data in 3 parts for train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(train_ratio=0.75, test_ratio=0.10, validation_ratio=0.15):\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    s = (data.dtypes == 'object')\n",
    "    object_cols = list(s[s].index)\n",
    "    label_data = data.copy()\n",
    "    for col in object_cols:\n",
    "        label_encoder.fit(data[col])\n",
    "        label_data[col] = label_encoder.transform(data[col])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(label_data.drop('Сдал', axis = 1), label_data['Сдал'], test_size=1 - train_ratio, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_ratio/(test_ratio + validation_ratio), random_state=1)\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will be replaced by train_test_val_split()\n",
    "def evel_split():\n",
    "    train = data.loc[:346, :]\n",
    "    val = data.loc[347:, :].drop('Сдал', axis = 1)\n",
    "\n",
    "    s = (train.dtypes == 'object')\n",
    "    object_cols = list(s[s].index)\n",
    "\n",
    "\n",
    "    label_train = train.copy()\n",
    "    label_val = val.copy()\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in object_cols:\n",
    "        label_encoder.fit(data[col])\n",
    "        label_train[col] = label_encoder.transform(train[col])\n",
    "        label_val[col] = label_encoder.transform(val[col])\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(label_train.drop('Сдал', axis = 1), \n",
    "                                                        label_train['Сдал'], test_size=0.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = evel_split()\n",
    "#X_train, X_test, X_val, y_train, y_test, y_val = train_test_val_split(train_ratio=0.75, test_ratio=0.10, validation_ratio=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model variants\n",
    "In that part I will choose the classification model which will predict if student pass exams successfully or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_quality(y_test, y_pred):\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"F1:\", f1_score(y_test, y_pred, average='macro', labels=np.unique(y_pred)))\n",
    "    print(\"Weighted Recall:\", (precision_recall_fscore_support(y_test, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_quality(y_test, y_pred):\n",
    "    print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE:\", mean_squared_error(y_test, y_pred)**(1/2))\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"R2:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = ['Accuracy', 'Balanced Accuracy', 'Recall', 'Precision', 'F1', 'MSE', 'RMSE', 'MAE', 'R2']\n",
    "model_array = []\n",
    "output_array = []\n",
    "\n",
    "def compilance_print(model, y_test, y_pred, model_flag):\n",
    "    temp_array = []\n",
    "    if model_flag == 'cls': # classifier\n",
    "        temp_array.append(accuracy_score(y_test, y_pred))\n",
    "        temp_array.append(balanced_accuracy_score(y_test, y_pred))\n",
    "        temp_array.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        temp_array.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        temp_array.append(f1_score(y_test, y_pred, average='macro', labels=np.unique(y_pred)))\n",
    "        for i in range(4): temp_array.append(None)\n",
    "    elif model_flag == 'reg': # regression\n",
    "        for i in range(5): temp_array.append(None)\n",
    "        temp_array.append(mean_squared_error(y_test, y_pred))\n",
    "        temp_array.append(mean_squared_error(y_test, y_pred)**(1/2))\n",
    "        temp_array.append(mean_absolute_error(y_test, y_pred))\n",
    "        temp_array.append(r2_score(y_test, y_pred))\n",
    "    else: \n",
    "        print('Error')\n",
    "        for i in range(len(metrics_list)): temp_array.append(None)\n",
    "\n",
    "    model_indx = -1\n",
    "    flag = 1\n",
    "    for indx, _model in enumerate(model_array):\n",
    "        if _model == model:\n",
    "            model_indx = indx\n",
    "            flag = 0\n",
    "    if flag:\n",
    "        output_array.append([0]* len(metrics_list))\n",
    "        model_indx = len(model_array)\n",
    "        model_array.append(model)\n",
    "    for indx, el in enumerate(temp_array):\n",
    "        output_array[model_indx][indx] = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_show(model, X_test, y_test):\n",
    "    metrics.plot_confusion_matrix(model, X_test, y_test) \n",
    "    metrics.plot_roc_curve(model, X_test, y_test)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perception Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "Perc = Perceptron()\n",
    "Perc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Perc.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('Perceptron', y_test, y_pred, 'cls')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RanF = RandomForestClassifier()\n",
    "RanF.fit(X_train, y_train)\n",
    "\n",
    "y_pred = RanF.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('RandomForest', y_test, y_pred, 'cls')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GraB = GradientBoostingClassifier()\n",
    "GraB.fit(X_train, y_train)\n",
    "\n",
    "y_pred = GraB.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('GradientBoosting', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MulNB = MultinomialNB()\n",
    "MulNB.fit(X_train, y_train)\n",
    "\n",
    "y_pred = MulNB.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('MultinomialNB', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComplementNB Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "ComNB = ComplementNB()\n",
    "ComNB.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ComNB.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('ComplementNB', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GaNB = GaussianNB()\n",
    "GaNB.fit(X_train, y_train)\n",
    "\n",
    "y_pred = GaNB.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('GaussianNB', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CategoricalNB Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "CatNB = CategoricalNB()\n",
    "CatNB.fit(X_train, y_train)\n",
    "\n",
    "y_pred = CatNB.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('CategoricalNB', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BernoulliNB Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "BerNB = BernoulliNB()\n",
    "BerNB.fit(X_train, y_train)\n",
    "\n",
    "y_pred = BerNB.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('BernoulliNB', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('SVC', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lsvc.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('LinearSVC', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneClassSVM Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "oclsvc = OneClassSVM()\n",
    "oclsvc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = oclsvc.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "#compilance_print('OneClassSVM', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtr = DecisionTreeClassifier()\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtr.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('DecisionTreeClassifier', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreeClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree, ExtraTreeClassifier\n",
    "extr = ExtraTreeClassifier()\n",
    "extr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = extr.predict(X_test)\n",
    "\n",
    "#plot_tree(extr)\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('ExtraTreeClassifier', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLPCl = MLPClassifier()\n",
    "MLPCl.fit(X_train, y_train)\n",
    "\n",
    "y_pred = MLPCl.predict(X_test)\n",
    "\n",
    "classification_quality(y_test, y_pred)\n",
    "compilance_print('MLPClassifier', y_test, y_pred, 'cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix\n",
    "That table helps to understand which model is better for my work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(index=metrics_list, columns=model_array, data=np.array(pd.DataFrame(output_array).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose model X due to its statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = MLPCl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('dataset.xlsx')\n",
    "students = data[347:].drop('Средний балл', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.loc[:, 'Сдал'] = my_model.predict(label_val)\n",
    "students.index += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students[students['Сдал'] == 0]['Учащийся']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbc59c1602769476583de30dcfaf94a717f95996dfb09063277734c10faa726c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
